package main

import (
	"context"
	"encoding/json"
	"flag"
	"fmt"
	"html/template"
	"log"
	"net/http"
	"os"
	"os/signal"
	"path/filepath"
	"reflect"
	"strings"
	"sync"
	"syscall"
	"time"

	"github.com/fsnotify/fsnotify"
	tgbotapi "github.com/go-telegram-bot-api/telegram-bot-api/v5"
	"gopkg.in/yaml.v2"
	corev1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/labels"
	"k8s.io/apimachinery/pkg/types"
	"k8s.io/apimachinery/pkg/watch"
	"k8s.io/client-go/kubernetes"
	"k8s.io/client-go/rest"
	"k8s.io/client-go/tools/clientcmd"
	"k8s.io/client-go/util/retry"
)

type Config struct {
	Telegram struct {
		Token  string `yaml:"token"`
		ChatID int64  `yaml:"chat_id"`
	} `yaml:"telegram"`

	HTTP struct {
		ListenAddr string `yaml:"listen_addr"` // é»˜è®¤ "0.0.0.0"
		Port       string `yaml:"port"`        // é»˜è®¤ "80"
	} `yaml:"http"`

	Maintenance struct {
		HTMLPath string `yaml:"html_path"` // é»˜è®¤ "/config/maintenance.html"
	} `yaml:"maintenance"`

	Switch struct {
		ForceSwitch bool `yaml:"force_switch"` // æ ¸å¿ƒå¼€å…³ï¼Œé»˜è®¤ false

		MaintenanceNamespace string `yaml:"maintenance_namespace"` // ç»´æŠ¤é¡µæœåŠ¡æ‰€åœ¨çš„å‘½åç©ºé—´
		MaintenanceService   string `yaml:"maintenance_service"`   // ç»´æŠ¤é¡µæœåŠ¡åç§°

		Targets []struct {
			Namespace string   `yaml:"namespace"`
			Services  []string `yaml:"services"` // æ”¯æŒå¤šä¸ª svc per namespace
		} `yaml:"targets"`
	} `yaml:"switch"`
}

var (
	configPath   = "/config/config.yaml"
	config       Config
	clientset    *kubernetes.Clientset
	bot          *tgbotapi.BotAPI
	mu           sync.RWMutex
	htmlTemplate *template.Template
	logger       = log.New(os.Stdout, "[traffic-switcher] ", log.LstdFlags)

	// ç”¨äºå­˜å‚¨æ¯ä¸ªç›®æ ‡æœåŠ¡çš„åŸå§‹ subsets
	originalSubsets sync.Map // key: "ns/svc" value: []corev1.EndpointSubset

	// ç›‘æ§åœæ­¢é€šé“
	stopCh sync.Map // key: "ns/svc" â†’ chan struct{}
)

func main() {
	var kubeconfig string
	flag.StringVar(&kubeconfig, "kubeconfig", "", "absolute path to the kubeconfig file")
	flag.Parse()

	// åˆå§‹åŒ– k8s client
	var err error
	var cfg *rest.Config
	if kubeconfig != "" {
		cfg, err = clientcmd.BuildConfigFromFlags("", kubeconfig)
	} else {
		cfg, err = rest.InClusterConfig()
	}
	if err != nil {
		logger.Fatalf("Failed to get kubernetes config: %v", err)
	}

	clientset, err = kubernetes.NewForConfig(cfg)
	if err != nil {
		logger.Fatalf("Failed to create kubernetes client: %v", err)
	}

	// é¦–æ¬¡åŠ è½½é…ç½®
	loadConfig()

	// å¯åŠ¨ http server
	go startHTTPServer()

	// ç›‘å¬é…ç½®æ–‡ä»¶å˜åŒ–
	go watchConfig()

	// ç­‰å¾…ç³»ç»Ÿä¿¡å·é€€å‡º
	sig := make(chan os.Signal, 1)
	signal.Notify(sig, syscall.SIGINT, syscall.SIGTERM)
	<-sig

	logger.Println("Shutting down...")
	// åœæ­¢æ‰€æœ‰ç›‘æ§
	stopCh.Range(func(key, value interface{}) bool {
		close(value.(chan struct{}))
		return true
	})
}

func loadConfig() {
	data, err := os.ReadFile(configPath)
	if err != nil {
		logger.Printf("Failed to read config: %v", err)
		return
	}

	var newConfig Config
	if err := yaml.Unmarshal(data, &newConfig); err != nil {
		logger.Printf("Failed to parse yaml: %v", err)
		return
	}

	mu.Lock()
	oldForce := config.Switch.ForceSwitch
	config = newConfig
	mu.Unlock()

	// é»˜è®¤å€¼
	if config.HTTP.ListenAddr == "" {
		config.HTTP.ListenAddr = "0.0.0.0"
	}
	if config.HTTP.Port == "" {
		config.HTTP.Port = "80"
	}
	if config.Maintenance.HTMLPath == "" {
		config.Maintenance.HTMLPath = "/config/maintenance.html"
	}
	if config.Switch.MaintenanceNamespace == "" {
		config.Switch.MaintenanceNamespace = "default"
	}
	if config.Switch.MaintenanceService == "" {
		config.Switch.MaintenanceService = "traffic-switcher"
	}

	// åŠ è½½ç»´æŠ¤é¡µé¢
	loadHTMLTemplate()

	// åˆå§‹åŒ– Telegram Bot
	if config.Telegram.Token != "" && config.Telegram.ChatID != 0 {
		var botErr error
		bot, botErr = tgbotapi.NewBotAPI(config.Telegram.Token)
		if botErr != nil {
			logger.Printf("Failed to init telegram bot: %v", botErr)
			bot = nil
		} else {
			logger.Printf("Telegram bot initialized: @%s", bot.Self.UserName)
		}
	}

	// å¼€å…³å˜åŒ–æ£€æµ‹
	shouldSwitch := config.Switch.ForceSwitch

	if shouldSwitch && !oldForce {
		logger.Println("Force switch turned ON -> switching to maintenance")
		switchToMaintenance()
		sendTelegram("ğŸš§ **Maintenance mode ACTIVATED**")
	} else if !shouldSwitch && oldForce {
		logger.Println("Force switch turned OFF -> recovering original traffic")
		recoverOriginal()
		sendTelegram("âœ… **Maintenance mode DEACTIVATED**, traffic recovered")
	}
}

func loadHTMLTemplate() {
	mu.Lock()
	defer mu.Unlock()

	tmpl, err := template.ParseFiles(config.Maintenance.HTMLPath)
	if err != nil {
		logger.Printf("Failed to load maintenance template %s: %v", config.Maintenance.HTMLPath, err)
		htmlTemplate = nil
		return
	}
	htmlTemplate = tmpl
	logger.Printf("Maintenance HTML loaded: %s", config.Maintenance.HTMLPath)
}

func startHTTPServer() {
	mux := http.NewServeMux()

	mux.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
		mu.RLock()
		tmpl := htmlTemplate
		mu.RUnlock()

		if tmpl == nil {
			http.Error(w, "Maintenance page not available", http.StatusInternalServerError)
			return
		}

		w.Header().Set("Content-Type", "text/html; charset=utf-8")
		_ = tmpl.Execute(w, nil)
	})

	addr := fmt.Sprintf("%s:%s", config.HTTP.ListenAddr, config.HTTP.Port)
	logger.Printf("Starting HTTP server on %s", addr)

	if err := http.ListenAndServe(addr, mux); err != nil {
		logger.Fatalf("HTTP server failed: %v", err)
	}
}

func watchConfig() {
	watcher, err := fsnotify.NewWatcher()
	if err != nil {
		logger.Fatalf("Failed to create fs watcher: %v", err)
	}
	defer watcher.Close()

	dir := filepath.Dir(configPath)
	if err := watcher.Add(dir); err != nil {
		logger.Fatalf("Failed to watch dir %s: %v", dir, err)
	}
	logger.Printf("Watching config directory: %s", dir)

	for {
		select {
		case event, ok := <-watcher.Events:
			if !ok {
				return
			}
			if event.Has(fsnotify.Write) || event.Has(fsnotify.Create) {
				if strings.HasSuffix(event.Name, "config.yaml") || strings.HasSuffix(event.Name, "maintenance.html") {
					logger.Printf("Detected change in %s, reloading...", event.Name)
					loadConfig()
				}
			}
		case err, ok := <-watcher.Errors:
			if !ok {
				return
			}
			logger.Printf("fsnotify error: %v", err)
		}
	}
}

func switchToMaintenance() {
	// è·å–ç»´æŠ¤é¡µæœåŠ¡çš„å½“å‰ subsets
	maintenanceEp, err := clientset.CoreV1().Endpoints(config.Switch.MaintenanceNamespace).Get(context.Background(), config.Switch.MaintenanceService, metav1.GetOptions{})
	if err != nil {
		logger.Printf("Failed to get maintenance endpoints %s/%s: %v", config.Switch.MaintenanceNamespace, config.Switch.MaintenanceService, err)
		return
	}
	maintenanceSubsets := maintenanceEp.Subsets

	if len(maintenanceSubsets) == 0 {
		logger.Println("Maintenance service has no subsets, cannot switch")
		return
	}

	for _, group := range config.Switch.Targets {
		for _, svc := range group.Services {
			key := fmt.Sprintf("%s/%s", group.Namespace, svc)

			// ä¿å­˜åŸå§‹ subsets
			targetEp, err := clientset.CoreV1().Endpoints(group.Namespace).Get(context.Background(), svc, metav1.GetOptions{})
			if err != nil {
				logger.Printf("Failed to get target %s: %v", key, err)
				continue
			}
			if _, loaded := originalSubsets.Load(key); !loaded {
				originalSubsets.Store(key, targetEp.Subsets)
				logger.Printf("Saved original subsets for %s", key)
			}

			// è¦†ç›– subsets
			patchSubsets(group.Namespace, svc, maintenanceSubsets)

			// å¯åŠ¨ç›‘æ§ï¼ˆæ‹¦æˆªæ¨¡å¼ï¼‰
			ch := make(chan struct{})
			stopCh.Store(key, ch)
			go monitorEndpoints(group.Namespace, svc, maintenanceSubsets, ch)
		}
	}
}

func recoverOriginal() {
	for _, group := range config.Switch.Targets {
		for _, svc := range group.Services {
			key := fmt.Sprintf("%s/%s", group.Namespace, svc)

			// å…ˆåœæ­¢ç›‘æ§ï¼ˆå…³é—­æ‹¦æˆªæ¨¡å¼ï¼‰
			if chI, loaded := stopCh.LoadAndDelete(key); loaded {
				close(chI.(chan struct{}))
				logger.Printf("Stopped monitor (interception disabled) for %s", key)
			}

			// æ¢å¤åŸå§‹ subsets
			if raw, loaded := originalSubsets.LoadAndDelete(key); loaded {
				subsets := raw.([]corev1.EndpointSubset)
				patchSubsets(group.Namespace, svc, subsets)
				logger.Printf("Recovered original subsets for %s", key)
			}

			// é‡å¯å…³è” Deployment
			restartAssociatedDeployment(group.Namespace, svc)
		}
	}
}

func patchSubsets(namespace, svc string, subsets []corev1.EndpointSubset) {
	patchData, err := json.Marshal(map[string]interface{}{"subsets": subsets})
	if err != nil {
		logger.Printf("Failed to marshal patch for %s/%s: %v", namespace, svc, err)
		return
	}

	err = retry.RetryOnConflict(retry.DefaultRetry, func() error {
		_, err := clientset.CoreV1().Endpoints(namespace).Patch(context.Background(), svc, types.MergePatchType, patchData, metav1.PatchOptions{})
		return err
	})
	if err != nil {
		logger.Printf("Failed to patch %s/%s: %v", namespace, svc, err)
	} else {
		logger.Printf("Patched %s/%s successfully", namespace, svc)
	}
}

func monitorEndpoints(namespace, svc string, desiredSubsets []corev1.EndpointSubset, stop chan struct{}) {
	logger.Printf("Starting interception monitor for %s/%s", namespace, svc)

	for {
		select {
		case <-stop:
			logger.Printf("Interception monitor stopped for %s/%s", namespace, svc)
			return
		default:
			watcher, err := clientset.CoreV1().Endpoints(namespace).Watch(context.Background(), metav1.ListOptions{
				FieldSelector: fmt.Sprintf("metadata.name=%s", svc),
			})
			if err != nil {
				logger.Printf("Failed to start watch for %s/%s: %v, retrying in 5s...", namespace, svc, err)
				time.Sleep(5 * time.Second)
				continue
			}

			for event := range watcher.ResultChan() {
				if event.Type == watch.Modified {
					ep := event.Object.(*corev1.Endpoints)
					if !reflect.DeepEqual(ep.Subsets, desiredSubsets) {
						logger.Printf("Detected unauthorized change on %s/%s, intercepting and re-patching...", namespace, svc)
						patchSubsets(namespace, svc, desiredSubsets)
					}
				}
			}

			watcher.Stop()
			logger.Printf("Watch channel closed for %s/%s, restarting watch...", namespace, svc)
			time.Sleep(5 * time.Second)
		}
	}
}

func restartAssociatedDeployment(namespace, svc string) {
	// è·å– service selector
	service, err := clientset.CoreV1().Services(namespace).Get(context.Background(), svc, metav1.GetOptions{})
	if err != nil {
		logger.Printf("Failed to get service %s/%s for restart: %v", namespace, svc, err)
		return
	}

	selector := labels.SelectorFromSet(service.Spec.Selector)
	if selector.Empty() {
		logger.Printf("Service %s/%s has no selector, cannot restart deployment", namespace, svc)
		return
	}

	// åˆ—å‡ºåŒ¹é…çš„ Deployment
	deployments, err := clientset.AppsV1().Deployments(namespace).List(context.Background(), metav1.ListOptions{
		LabelSelector: selector.String(),
	})
	if err != nil {
		logger.Printf("Failed to list deployments for %s/%s: %v", namespace, svc, err)
		return
	}

	if len(deployments.Items) == 0 {
		logger.Printf("No deployments found for service %s/%s", namespace, svc)
		return
	}

	for _, dep := range deployments.Items {
		// ä½¿ç”¨ annotation è§¦å‘ rolling restart
		patch := []byte(fmt.Sprintf(`{"spec":{"template":{"metadata":{"annotations":{"kubectl.kubernetes.io/restartedAt":"%s"}}}}}`, time.Now().Format(time.RFC3339)))
		_, err := clientset.AppsV1().Deployments(namespace).Patch(context.Background(), dep.Name, types.StrategicMergePatchType, patch, metav1.PatchOptions{})
		if err != nil {
			logger.Printf("Failed to restart deployment %s: %v", dep.Name, err)
		} else {
			logger.Printf("Triggered rolling restart for deployment %s", dep.Name)
		}
	}
}

func sendTelegram(msg string) {
	if bot == nil {
		return
	}

	message := tgbotapi.NewMessage(config.Telegram.ChatID, msg)
	message.ParseMode = "Markdown"

	if _, err := bot.Send(message); err != nil {
		logger.Printf("Failed to send telegram: %v", err)
	} else {
		logger.Printf("Telegram sent: %s", msg)
	}
}